---
layout: book-review
title: "Learning Theory from First Principles"
author: Francis Bach
cover: assets/img/book_covers/learning_theory.jpg
status: Finished
---

Following the course by Francis Bach at M2 IASD, this book provided me with a solid foundation in learning theory. It offers a rigorous introduction to the mathematical foundations of machine learning, emphasizing a "first principles" approach. It bridges the gap between optimization theory and statistical learning.

**Key Topics Covered:**
*   **Uniform Deviation Principles:** The foundation of statistical learning theory.
*   **Optimization:** Gradient descent, stochastic gradient descent (SGD), and acceleration methods (Nesterov).
*   **Kernel Methods:** Reproducing Kernel Hilbert Spaces (RKHS) and the representer theorem.
*   **Statistical Guarantees:** Generalization bounds, Rademacher complexity, and consistency.
*   **Sparsity:** Lasso, compressed sensing, and proximal methods.
*   **Neural Networks:** Deep learning and the universal approximation theorem.
*   **Advanced Topics:** Online learning, double descent and generalization.

I rely on this book for its precise mathematical treatment of algorithms, ensuring a solid grasp of *why* learning algorithms work and their convergence properties.
